
#
# AI教育セミナー「Cancer Informatics Seminar」参加報告書
・提出日：2023/03/28 <br>

・遺伝子解析センター第2部　内山友哉 <br>
・主催：国立がん研究センター東病院、株式会社ヒューマノーム研究所 <br>
・開催日：2023/01/10 - 03/28 (毎週火曜日、17:30-19:00) <br>
・参加日：2023/03/07、14、28 <br>
・開催場所：国立がん研究センター東病院（ハイブリッド開催のため、webで参加）<br>

【参加目的】<br>
　演習形式のAI・機械学習セミナー講義からの学習を通じて、有用なシーズ配列探索などの新規解析手法や製造業務効率化の提案・運用につなげる。<br>

【総括】<br>
　近年、ChatGPTで話題になったようにAI研究の発展は著しく、生物学や医学分野においてもAI技術を紐づけた解析手法やAIを用いて標的候補の探索を短時間で行った文献数も著しく増加している。それに加えて、機械学習を用いたデータ解析に関しても、データの前処理からパラメータチューニングを含む学習モデルの選択までの一連の解析プロセスを自動化するツールもwebで公開され、広く認知され始めてきた。つまり、データを用意するだけでモデル構築の知識が皆無でも分析できるような時代に突入してきたと個人的に感じた。しかし、現在のAIシステムは大量のデータからルールを自動的に生成するため、人間が問題設定を正しく行わなければならない。そのため、生物学や医療分野に対しては、第3者がアクセスできるデータを大量かつ容易に入手できないことや複雑なシステムを有し、ドメイン知識を必要とすることから、AIを用いた解析プロセスは自動化できていないどころか未整備である。今後、生物学をより発展させるためには少量のデータからでも有用な特徴量を生成する仕組みを理解することや、難題を要するが未知数であるAI（特に1次関数の集合体による機械学習手法であるDeep Learning）を用いた標的候補探索に向けた解析手法の理解とその構築への挑戦も必要ではないのかと思った。<br>


### ● 生物学におけるAI活用例について
* ゲノム配列の機能を予測するAI <br>
    - ゲノム配列から、メチル化等の情報を予測したり、特定細胞の遺伝子発現を予測する <br>
    - 計算機上で、擬似的な変異を与えることでゲノムの変異が細胞内でどのような変化を起こすのかを予測する <br>
    - アミノ酸配列が与えられた時に立体構造を予測する(Alpha) <br>
* 創薬への発展 <br>
    - Genentechが8年がかりで見出したキナーゼ阻害剤の性能と同等以上のものを21日で複数の候補を設計。<br>
    - 設計 → 合成 → 評価までわずか46日 <br>
* まとめ <br>
    - AIはすでにがんを始めとする医学分野の研究に活用されている。<br>
    - 診断機器として承認を受けているものもあり、活用が進んでいる。<br>
    - ITシステムとAIシステムの主要な違いについては、ITシステムでは人間が計算機に判定ルールを直接与えるのに対して、AIシステムでは人間が明示的に与えるのではなく、与えられたデータからルールを自動的に生成し、自動的に判定できるようになること。<br>

### ● 第8回講義（開催日：2023/03/07）
本講義では、従来のカプランマイヤー法と同様に患者ごとの生存時間を診断情報から予測する解析手法が紹介された。これは、今後コホート研究の解析メニューを拡張を図る内容ではないかと考えられた。<br>

* 生存解析について <br>
    - クラス分類（打ち切りかどうか）でも回帰（最後の計測時点）でもない。
    - 生存曲線のデータは、診断情報、打ち切り（治療やめたのか、亡くなったののか）consored（最終的に計測できたかどうか）と最終計測時点の時間（生存時間）の2つがペアになったデータ。回帰やクラス分類のデータのように、診断情報と予測したい1つの値がペアになったデータとは異なる。<br>
    → 説明変数は年齢や性別、検査時の値のような診療データに、応答変数は打ち切りの情報と生存時間のような生存解析に関連したデータに対応しているイメージ。<br>
    → 生存曲線を予測する学習は医療分野以外では使われていないので、汎用性の高いデータ解析プロセスのみを自動化したAutoMLでは対応できていない。<br>

```bash
# 診断データ例（scikit-survivalに実装されているデータを示す）
	afb	age	av3	bmi	chf	cvd	diasbp	gender	hr	los	miord	mitype	sho	sysbp
0	1	83.0	0	25.54051	0	1	78.0	0	89.0	5.0	1	0	0	152.0
1	0	49.0	0	24.02398	0	1	60.0	0	84.0	5.0	0	1	0	120.0
2	0	70.0	0	22.14290	0	0	88.0	1	83.0	5.0	0	1	0	147.0
3	0	70.0	0	26.63187	1	1	76.0	0	65.0	10.0	0	1	0	123.0
4	0	70.0	0	24.41255	0	1	85.0	0	63.0	6.0	0	1	0	135.0
```
```bash
# 打ち切りの情報と生存時間データの例（scikit-survivalに実装されているデータを示す）
# fstatがFalseのときは打ち切りを表している。
	fstat	lenfol
0	False	2178.0
1	False	2172.0
2	False	2190.0
3	True	297.0
4	False	2131.0
```

* 機械学習による予測
    - ある被験者に着目し、その被験者の診断情報を入力したときに、その人の期間ごとの生存率を表す曲線をC-index法で予測する。
    - 利用ライブラリーはscikit-survivalで、RandomForestの手法を生存解析に拡張したものとなっている。

* C-index（Concordance index)　とは
    - 生存解析でよく用いられる手法。
    - 生存曲線の違いを群間で比較するCox比較ハザードモデルで利用される指標のうちの1つ。
    - 予測した生存期間の順序と実際の生存期間の順序を比較し、一致する確率を示す。
    - 0-1の値を取り、1に近いほど一致確率が高い。
    - 全パターン計算し、前の人（早く診療にきた人）が、後に診療にきた人よりも早く亡くなるような確率を求める。1ならば上記の状況で時系列的には矛盾はない、0ならば、後に診療にきた人の方が長く生きている。

* 予測モデルの作成
    - C-indexが最大となるようなモデルを作成（予測精度ができるだけ高くなるようなもモデル）
    - C-indexは被験者の順番が決まると、値が決まるので被験者の順番を求める問題となっている。
    - 状況がわからない打ち切りは無視して、どれだけ長く生きるかを予測している。


### ● 第9、10回講義（開催日：2023/03/14、28）
　公共データcBioPortal for Cancer Genomics内のMSK Impactのデータ解析を、一連の解析プロセスを自動化するツールpycaretで実施する内容であった。解析内容としては、MSK Imapctで得られている各被験者の変異情報からがん腫を予測するというものであった。紹介された解析では、MSK Impactで最も被験者数が多かった2つのがん種、乳がん（Non-Small Cell Lung Cancer）と肺がん（Breast Cancer）に絞って分類予測を実施していた（サンプル数は各々1620と1291）。しかし、実際の解析では、特定の疾患患者のデータの収集は困難であるが、健常者のデータは比較的容易に収集できることが想定される。しかし、今回のハンズオンのように通常の分類問題における機械学習のアルゴリズムはサンプル数が同程度であることを想定して実装されていることが多いため、サンプル数が著しく偏っている状況下では分類モデルの学習が困難になり、分類精度が著しく低下することが知られている（対象とするクラスの頻度分布が互いに重なってしまうため）。そのため、実際の実験から得られたデータを解析する際には、現状pycaretをそのまま使うのではなく、データの特徴量や使えそうな学習モデルの把握を短時間で実施するのが



・講義で出題された問題例が分類問題だったので、以下のような回帰分析を行った。<br>
遺伝子変異情報を含む患者情報から、あるがん腫を患う生存率を予測する <br>
ただし、以下のような条件を満たすがん腫を対象に解析を行った。<br>
```bash
・1患者あたりのサンプル数は1つである。
・変異タイプはpoint mutationに着目。
・患者IDとサンプルIDが1対1で紐づいている。
・がん腫ごとのサンプル数が多い順に並べた時にそのがん腫の患者の男女比が1:1。
```
→ MSK Imapctでこれらの条件を満たすがん腫は、大腸がんであることが分かった（n=648）。これより、<br>

```bash
# 必要な情報の抽出
[uchiyamat@gifu: ~/TEST/case_lists-20230328T042300Z-001]$ cut -f3,6,7,9,10,12-14,18-21,23,25,26 msk_impact_2017_clinical_data.tsv > msk_impact_2017_clinical_data.mod.tsv

```
```bash
[uchiyamat@gifu: ~/TEST/case_lists-20230328T042300Z-001/msk_impact_2017]$ pip install pycaret==3.0.0rc9
```

### 所感
多くの手順を、データの確認や結合などの前処理に費やしていますが、実際時間がかかります
多くの部分、問題設定をする先生方と、解析者􏰀間で摺合せを行って、決めていく必要がある


### ● 補足調査
* AutoML（Automated Machine Learning）について<br>
    - 参考: https://qiita.com/y-vectorfield/items/6b345e3631e0d63e6d0b
    - 機械学習を用いたデータ分析のプロセスを自動化することやその技術全般を示す。
    - AutoMLでは以下の行程を自動化。
        - データの前処理
        - 特徴量エンジニアリング
        - モデルの構築と精度の比較
        - パラメータチューニング
        - アンサンブル学習

<br>

* AutoMLライブラリーPyCaretについて
    - MLのワークフローを自動化出来る
    - 指数関数的に実行時間を高速化し、生産性を高める
    - (他のライブラリでは)数100行にも及ぶ様なコードを僅か数行のコードで実現
    - scikit-learnやXGBoost、OptunaなどのMLライブラリのラッパーである
    - シンプルで程良く洗練された分析タスクを簡単に実現出来る

* メリット
    - 極端な言い方をするとデータを用意するだけでMLモデル構築の知識が皆無でも分析が出来る
    - 手持ちのデータに対して有効なモデルが分からず、兎に角多くのモデルで試した結果を知りたい場合に最小限の労力で分析が出来る
    - 最良の結果にはマーカ付きで表示され結果の比較・検討が容易になる
    - 実行後の結果を可視化する機能まで含まれており、分析の結果を共有することも容易
    - Jupyter Notebookと組み合わせて使用すれば分析レポートを作るのも容易となる <br>
* デメリット
    - 少しパラメータを変化させて検証したいといった細かいチューニングは難しい
    - 様々なモデルを一気に動作させることが出来るのは利点であると同時に、ブラックボックス化に拍車を掛けてしまう部分が有る
    - feature_selection等のoptionを利用した時に、内部で何が起こっているのかよく分からない
    - (PyCaretの場合)Deep Learningはそもそも対象外であり、比較対象に出来ない
    - アップデートのスピードが緩やかであり、最新の環境への対応に時間がかかる。(PyCaretの場合)Python3.10移行には非対応(Ver3.0から対応予定)




o	アンサンブル学習
・参考：【機械学習】ランダムフォレストを理解する https://qiita.com/Hawaii/items/5831e667723b66b46fba

・弱分類器と呼ばれる複数のモデルを学習させて、その複数のモデルの結果を統合する集団学習のことをいう。
・弱分類器には任意のモデルが利用できるが、SVM、木構造を用いた決定木、回帰が用いられる。
・「バギング」と「ブースティング」の2種類のやり方がある。
・バギングは多数の弱分類器を独立して学習させるが、ブースティングは1つずつ順番に弱分類器を学習させて、以前に学習した弱分類器の結果を取り込む。
　→ バギングは並列に学習できるが、ブースティングは学習を並列化できない。

・決定木：サンプルに対して様々な条件を比較して分岐させていくことで、分類や回帰を行うモデル。
・CART(Classification and Regression Tree)と呼ばれるアルゴリズムが有名。
・ジニ不純度と呼ばれる指標で分類の精度を評価。着目しているノードに含まれるサンプルをどの程度正しく分類できたか？
・CARTの学習では、全体のジニ不純度が小さくなるように学習。
・m番目の変数のノードによってジニ不純度の改善した場合は、CARTにおけるm番目の変数の重要度を示す。

・バギング（bagging）：ブートストラップ・アグリゲーションの略。
・ブートストラップとは、元データを復元抽出でサンプリングする方法。1度取ったデータもまた元に戻してサンプリングするので同じデータが何回も選ばれる可能性がある。
・ランダムフォレストでは、決定木を弱分類器として採用したアンサンブル学習のこと。
　→ 多数の決定木を集めてフォレストにする。分類であれば、多数決、回帰であれば平均で予測を行う。

・ブースティング：弱分類器の学習を進めるごとに、その弱点を修正していくイメージ。バギングよりも高い性能を得られやすい。AdaBoostアルゴリズム。

・決定木を用いた回帰の仕組みについて

・領域に合わせて条件分岐を行う
・分岐の前後の平均値との2乗誤差を計算。

誤差が小さくなるような条件分岐を選択し、領域ごとのデータの平均値をとる




